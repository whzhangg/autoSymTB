
@article{xie_crystal_2018,
	title = {Crystal {Graph} {Convolutional} {Neural} {Networks} for an {Accurate} and {Interpretable} {Prediction} of {Material} {Properties}},
	volume = {120},
	issn = {0031-9007, 1079-7114},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.120.145301},
	doi = {10.1103/PhysRevLett.120.145301},
	language = {en},
	number = {14},
	urldate = {2021-11-30},
	journal = {Physical Review Letters},
	author = {Xie, Tian and Grossman, Jeffrey C.},
	month = apr,
	year = {2018},
	keywords = {Crystal Graph Networks (CGCNN), Solid state compounds},
	pages = {145301},
	file = {Xie and Grossman - 2018 - Crystal Graph Convolutional Neural Networks for an.pdf:/Users/wenhao/work/zotero/storage/CIK8MLXU/Xie and Grossman - 2018 - Crystal Graph Convolutional Neural Networks for an.pdf:application/pdf;Xie and Grossman - Supplemental Material Crystal Graph Convolutional.pdf:/Users/wenhao/work/zotero/storage/PYXH9YZF/Xie and Grossman - Supplemental Material Crystal Graph Convolutional.pdf:application/pdf},
}

@article{chen_graph_2019,
	title = {Graph {Networks} as a {Universal} {Machine} {Learning} {Framework} for {Molecules} and {Crystals}},
	volume = {31},
	issn = {0897-4756, 1520-5002},
	url = {https://pubs.acs.org/doi/10.1021/acs.chemmater.9b01294},
	doi = {10.1021/acs.chemmater.9b01294},
	abstract = {Graph networks are a new machine learning (ML) paradigm that supports both relational reasoning and combinatorial generalization. Here, we develop universal MatErials Graph Network (MEGNet) models for accurate property prediction in both molecules and crystals. We demonstrate that the MEGNet models outperform prior ML models such as the SchNet in 11 out of 13 properties of the QM9 molecule data set. Similarly, we show that MEGNet models trained on ∼60 000 crystals in the Materials Project substantially outperform prior ML models in the prediction of the formation energies, band gaps, and elastic moduli of crystals, achieving better than density functional theory accuracy over a much larger data set. We present two new strategies to address data limitations common in materials science and chemistry. First, we demonstrate a physically intuitive approach to unify four separate molecular MEGNet models for the internal energy at 0 K and room temperature, enthalpy, and Gibbs free energy into a single free energy MEGNet model by incorporating the temperature, pressure, and entropy as global state inputs. Second, we show that the learned element embeddings in MEGNet models encode periodic chemical trends and can be transfer-learned from a property model trained on a larger data set (formation energies) to improve property models with smaller amounts of data (band gaps and elastic moduli).},
	language = {en},
	number = {9},
	urldate = {2021-11-30},
	journal = {Chemistry of Materials},
	author = {Chen, Chi and Ye, Weike and Zuo, Yunxing and Zheng, Chen and Ong, Shyue Ping},
	month = may,
	year = {2019},
	keywords = {Crystal Graph Networks},
	pages = {3564--3572},
	file = {Chen et al. - 2019 - Graph Networks as a Universal Machine Learning Fra.pdf:/Users/wenhao/work/zotero/storage/JMFN6XVQ/Chen et al. - 2019 - Graph Networks as a Universal Machine Learning Fra.pdf:application/pdf},
}

@article{schutt_schnet_2018,
	title = {{SchNet} – {A} deep learning architecture for molecules and materials},
	volume = {148},
	issn = {0021-9606, 1089-7690},
	url = {http://aip.scitation.org/doi/10.1063/1.5019779},
	doi = {10.1063/1.5019779},
	language = {en},
	number = {24},
	urldate = {2021-12-17},
	journal = {The Journal of Chemical Physics},
	author = {Schütt, K. T. and Sauceda, H. E. and Kindermans, P.-J. and Tkatchenko, A. and Müller, K.-R.},
	month = jun,
	year = {2018},
	keywords = {Tensor neural network},
	pages = {241722},
	file = {Schütt et al. - 2018 - SchNet – A deep learning architecture for molecule.pdf:/Users/wenhao/work/zotero/storage/AH4ZUGJE/Schütt et al. - 2018 - SchNet – A deep learning architecture for molecule.pdf:application/pdf},
}

@article{schutt_quantum-chemical_2017,
	title = {Quantum-chemical insights from deep tensor neural networks},
	volume = {8},
	issn = {2041-1723},
	url = {http://www.nature.com/articles/ncomms13890},
	doi = {10.1038/ncomms13890},
	language = {en},
	number = {1},
	urldate = {2021-12-17},
	journal = {Nature Communications},
	author = {Schütt, Kristof T. and Arbabzadah, Farhad and Chmiela, Stefan and Müller, Klaus R. and Tkatchenko, Alexandre},
	month = apr,
	year = {2017},
	keywords = {Molecular, Tensor neural network},
	pages = {13890},
	file = {Schütt et al. - 2017 - Quantum-chemical insights from deep tensor neural .pdf:/Users/wenhao/work/zotero/storage/IK8W7WPM/Schütt et al. - 2017 - Quantum-chemical insights from deep tensor neural .pdf:application/pdf},
}

@book{sakurai_modern_1994,
	address = {Reading, Mass},
	edition = {Rev. ed},
	title = {Modern quantum mechanics},
	isbn = {978-0-201-53929-5},
	publisher = {Addison-Wesley Pub. Co},
	author = {Sakurai, J. J. and Tuan, San Fu},
	year = {1994},
	keywords = {Quantum theory},
}

@book{goodfellow_deep_2016,
	address = {Cambridge, Massachusetts},
	series = {Adaptive computation and machine learning},
	title = {Deep learning},
	isbn = {978-0-262-03561-3},
	publisher = {The MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016},
	keywords = {Machine learning},
}

@article{wu_comprehensive_2021,
	title = {A {Comprehensive} {Survey} on {Graph} {Neural} {Networks}},
	volume = {32},
	issn = {2162-237X, 2162-2388},
	url = {http://arxiv.org/abs/1901.00596},
	doi = {10.1109/TNNLS.2020.2978386},
	abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classiﬁcation and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed signiﬁcant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning ﬁelds. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing ﬁeld.},
	language = {en},
	number = {1},
	urldate = {2022-02-17},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
	month = jan,
	year = {2021},
	note = {arXiv: 1901.00596},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {4--24},
	file = {noted version:/Users/wenhao/work/zotero/storage/LBHP2VPU/noted version.pdf:application/pdf;Wu et al. - 2021 - A Comprehensive Survey on Graph Neural Networks.pdf:/Users/wenhao/work/zotero/storage/PMWMCMD9/Wu et al. - 2021 - A Comprehensive Survey on Graph Neural Networks.pdf:application/pdf},
}

@article{cohen_spherical_2018,
	title = {Spherical {CNNs}},
	url = {http://arxiv.org/abs/1801.10130},
	abstract = {Convolutional Neural Networks (CNNs) have become the method of choice for learning problems involving 2D planar images. However, a number of problems of recent interest have created a demand for models that can analyze spherical images. Examples include omnidirectional vision for drones, robots, and autonomous cars, molecular regression problems, and global weather and climate modelling. A naive application of convolutional networks to a planar projection of the spherical signal is destined to fail, because the space-varying distortions introduced by such a projection will make translational weight sharing ineffective.},
	language = {en},
	urldate = {2022-01-25},
	journal = {arXiv:1801.10130 [cs, stat]},
	author = {Cohen, Taco S. and Geiger, Mario and Koehler, Jonas and Welling, Max},
	month = feb,
	year = {2018},
	note = {arXiv: 1801.10130},
	keywords = {Convolution network, equivariant convolution, Spherical images},
	file = {Cohen et al. - 2018 - Spherical CNNs.pdf:/Users/wenhao/work/zotero/storage/KTIX66EP/Cohen et al. - 2018 - Spherical CNNs.pdf:application/pdf;with notes - Spherical CNNs.pdf:/Users/wenhao/work/zotero/storage/7DP6I3AT/with notes - Spherical CNNs.pdf:application/pdf},
}

@article{cohen_group_2016,
	title = {Group {Equivariant} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1602.07576},
	abstract = {We introduce Group equivariant Convolutional Neural Networks (G-CNNs), a natural generalization of convolutional neural networks that reduces sample complexity by exploiting symmetries. G-CNNs use G-convolutions, a new type of layer that enjoys a substantially higher degree of weight sharing than regular convolution layers. G-convolutions increase the expressive capacity of the network without increasing the number of parameters. Group convolution layers are easy to use and can be implemented with negligible computational overhead for discrete groups generated by translations, reflections and rotations. G-CNNs achieve state of the art results on CIFAR10 and rotated MNIST.},
	urldate = {2022-02-04},
	journal = {arXiv:1602.07576 [cs, stat]},
	author = {Cohen, Taco S. and Welling, Max},
	month = jun,
	year = {2016},
	note = {arXiv: 1602.07576},
	keywords = {equivariant convolution},
	file = {Cohen and Welling - 2016 - Group Equivariant Convolutional Networks.pdf:/Users/wenhao/work/zotero/storage/XIDI95GR/Cohen and Welling - 2016 - Group Equivariant Convolutional Networks.pdf:application/pdf;Cohen et al. - Group Equivariant Convolutional Networks supplemen.pdf:/Users/wenhao/work/zotero/storage/2NTBBH9T/Cohen et al. - Group Equivariant Convolutional Networks supplemen.pdf:application/pdf},
}

@article{gilmer_neural_2017,
	title = {Neural {Message} {Passing} for {Quantum} {Chemistry}},
	url = {http://arxiv.org/abs/1704.01212},
	abstract = {Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to ﬁnd a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.},
	language = {en},
	urldate = {2022-02-15},
	journal = {arXiv:1704.01212 [cs]},
	author = {Gilmer, Justin and Schoenholz, Samuel S. and Riley, Patrick F. and Vinyals, Oriol and Dahl, George E.},
	month = jun,
	year = {2017},
	note = {arXiv: 1704.01212},
	file = {Gilmer et al. - 2017 - Neural Message Passing for Quantum Chemistry.pdf:/Users/wenhao/work/zotero/storage/UDPEPS5V/Gilmer et al. - 2017 - Neural Message Passing for Quantum Chemistry.pdf:application/pdf},
}

@book{serre_linear_1996,
	address = {New York},
	edition = {Corr. 5th print},
	series = {Graduate texts in mathematics},
	title = {Linear representations of finite groups},
	isbn = {978-0-387-90190-9 978-3-540-90190-7},
	language = {eng},
	number = {42},
	publisher = {Springer-Verlag},
	author = {Serre, Jean-Pierre},
	year = {1996},
	keywords = {Finite groups, Representations of groups},
}

@inproceedings{weiler_learning_2018,
	address = {Salt Lake City, UT},
	title = {Learning {Steerable} {Filters} for {Rotation} {Equivariant} {CNNs}},
	isbn = {978-1-5386-6420-9},
	url = {https://ieeexplore.ieee.org/document/8578193/},
	doi = {10.1109/CVPR.2018.00095},
	abstract = {In many machine learning tasks it is desirable that a model’s prediction transforms in an equivariant way under transformations of its input. Convolutional neural networks (CNNs) implement translational equivariance by construction; for other transformations, however, they are compelled to learn the proper mapping. In this work, we develop Steerable Filter CNNs (SFCNNs) which achieve joint equivariance under translations and rotations by design. The proposed architecture employs steerable ﬁlters to efﬁciently compute orientation dependent responses for many orientations without suffering interpolation artifacts from ﬁlter rotation. We utilize group convolutions which guarantee an equivariant mapping. In addition, we generalize He’s weight initialization scheme to ﬁlters which are deﬁned as a linear combination of a system of atomic ﬁlters. Numerical experiments show a substantial enhancement of the sample complexity with a growing number of sampled ﬁlter orientations and conﬁrm that the network generalizes learned patterns over orientations. The proposed approach achieves state-of-the-art on the rotated MNIST benchmark and on the ISBI 2012 2D EM segmentation challenge.},
	language = {en},
	urldate = {2022-02-08},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Weiler, Maurice and Hamprecht, Fred A. and Storath, Martin},
	month = jun,
	year = {2018},
	keywords = {steerable CNN},
	pages = {849--858},
	file = {Weiler et al_2018_Learning Steerable Filters for Rotation Equivariant CNNs.pdf:/Users/wenhao/work/zotero/storage/E7E2AHGY/Weiler et al_2018_Learning Steerable Filters for Rotation Equivariant CNNs.pdf:application/pdf},
}

@article{weiler_3d_2018,
	title = {{3D} {Steerable} {CNNs}: {Learning} {Rotationally} {Equivariant} {Features} in {Volumetric} {Data}},
	shorttitle = {{3D} {Steerable} {CNNs}},
	url = {http://arxiv.org/abs/1807.02547},
	abstract = {We present a convolutional network that is equivariant to rigid body motions. The model uses scalar-, vector-, and tensor ﬁelds over 3D Euclidean space to represent data, and equivariant convolutions to map between such representations. These SE(3)-equivariant convolutions utilize kernels which are parameterized as a linear combination of a complete steerable kernel basis, which is derived analytically in this paper. We prove that equivariant convolutions are the most general equivariant linear maps between ﬁelds over R3. Our experimental results conﬁrm the effectiveness of 3D Steerable CNNs for the problem of amino acid propensity prediction and protein structure classiﬁcation, both of which have inherent SE(3) symmetry.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:1807.02547 [cs, stat]},
	author = {Weiler, Maurice and Geiger, Mario and Welling, Max and Boomsma, Wouter and Cohen, Taco},
	month = oct,
	year = {2018},
	note = {arXiv: 1807.02547},
	keywords = {steerable CNN},
	file = {Weiler et al. - 2018 - 3D Steerable CNNs Learning Rotationally Equivaria.pdf:/Users/wenhao/work/zotero/storage/4IVCTB89/Weiler et al. - 2018 - 3D Steerable CNNs Learning Rotationally Equivaria.pdf:application/pdf},
}

@article{cohen_steerable_2016,
	title = {Steerable {CNNs}},
	url = {http://arxiv.org/abs/1612.08498},
	abstract = {It has long been recognized that the invariance and equivariance properties of a representation are critically important for success in many vision tasks. In this paper we present Steerable Convolutional Neural Networks, an efﬁcient and ﬂexible class of equivariant convolutional networks. We show that steerable CNNs achieve state of the art results on the CIFAR image classiﬁcation benchmark. The mathematical theory of steerable representations reveals a type system in which any steerable representation is a composition of elementary feature types, each one associated with a particular kind of symmetry. We show how the parameter cost of a steerable ﬁlter bank depends on the types of the input and output features, and show how to use this knowledge to construct CNNs that utilize parameters effectively.},
	language = {en},
	urldate = {2022-02-04},
	journal = {arXiv:1612.08498 [cs, stat]},
	author = {Cohen, Taco S. and Welling, Max},
	month = dec,
	year = {2016},
	note = {arXiv: 1612.08498},
	keywords = {steerable CNN},
	file = {Cohen and Welling - 2016 - Steerable CNNs.pdf:/Users/wenhao/work/zotero/storage/RRFJCIPP/Cohen and Welling - 2016 - Steerable CNNs.pdf:application/pdf},
}

@book{dresselhaus_group_2008,
	address = {Berlin},
	title = {Group theory: application to the physics of condensed matter},
	isbn = {978-3-540-32897-1},
	shorttitle = {Group theory},
	publisher = {Springer-Verlag},
	author = {Dresselhaus, M. S. and Dresselhaus, G. and Jorio, A.},
	year = {2008},
	note = {OCLC: ocn150354198},
	keywords = {Condensed matter, Group theory},
}

@article{thomas_tensor_2018,
	title = {Tensor field networks: {Rotation}- and translation-equivariant neural networks for {3D} point clouds},
	shorttitle = {Tensor field networks},
	url = {http://arxiv.org/abs/1802.08219},
	abstract = {We introduce tensor ﬁeld neural networks, which are locally equivariant to 3D rotations, translations, and permutations of points at every layer. 3D rotation equivariance removes the need for data augmentation to identify features in arbitrary orientations. Our network uses ﬁlters built from spherical harmonics; due to the mathematical consequences of this ﬁlter choice, each layer accepts as input (and guarantees as output) scalars, vectors, and higher-order tensors, in the geometric sense of these terms. We demonstrate the capabilities of tensor ﬁeld networks with tasks in geometry, physics, and chemistry.},
	language = {en},
	urldate = {2021-11-30},
	journal = {arXiv:1802.08219 [cs]},
	author = {Thomas, Nathaniel and Smidt, Tess and Kearnes, Steven and Yang, Lusann and Li, Li and Kohlhoff, Kai and Riley, Patrick},
	month = may,
	year = {2018},
	note = {arXiv: 1802.08219},
	keywords = {Tensor Neural Network, Network on points},
	file = {Thomas et al. - 2018 - Tensor field networks Rotation- and translation-e.pdf:/Users/wenhao/work/zotero/storage/NXNZFXLF/Thomas et al. - 2018 - Tensor field networks Rotation- and translation-e.pdf:application/pdf},
}

@article{klicpera_directional_2020,
	title = {Directional {Message} {Passing} for {Molecular} {Graphs}},
	url = {http://arxiv.org/abs/2003.03123},
	abstract = {Graph neural networks have recently achieved great successes in predicting quantum mechanical properties of molecules. These models represent a molecule as a graph using only the distance between atoms (nodes). They do not, however, consider the spatial direction from one atom to another, despite directional information playing a central role in empirical potentials for molecules, e.g. in angular potentials. To alleviate this limitation we propose directional message passing, in which we embed the messages passed between atoms instead of the atoms themselves. Each message is associated with a direction in coordinate space. These directional message embeddings are rotationally equivariant since the associated directions rotate with the molecule. We propose a message passing scheme analogous to belief propagation, which uses the directional information by transforming messages based on the angle between them. Additionally, we use spherical Bessel functions and spherical harmonics to construct theoretically well-founded, orthogonal representations that achieve better performance than the currently prevalent Gaussian radial basis representations while using fewer than 1/4 of the parameters. We leverage these innovations to construct the directional message passing neural network (DimeNet). DimeNet outperforms previous GNNs on average by 76\% on MD17 and by 31\% on QM9. Our implementation is available online.},
	language = {en},
	urldate = {2022-01-25},
	journal = {arXiv:2003.03123 [physics, stat]},
	author = {Klicpera, Johannes and Groß, Janek and Günnemann, Stephan},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.03123},
	file = {Klicpera et al. - 2020 - Directional Message Passing for Molecular Graphs.pdf:/Users/wenhao/work/zotero/storage/Q8TVRVGM/Klicpera et al. - 2020 - Directional Message Passing for Molecular Graphs.pdf:application/pdf},
}

@article{kondor_clebschgordan_2018,
	title = {Clebsch–{Gordan} {Nets}: a {Fully} {Fourier} {Space} {Spherical} {Convolutional} {Neural} {Network}},
	abstract = {Recent work by Cohen et al. [1] has achieved state-of-the-art results for learning spherical images in a rotation invariant way by using ideas from group representation theory and noncommutative harmonic analysis. In this paper we propose a generalization of this work that generally exhibits improved performace, but from an implementation point of view is actually simpler. An unusual feature of the proposed architecture is that it uses the Clebsch–Gordan transform as its only source of nonlinearity, thus avoiding repeated forward and backward Fourier transforms. The underlying ideas of the paper generalize to constructing neural networks that are invariant to the action of other compact groups.},
	language = {en},
	journal = {32nd Conference on Neural Information Processing Systems},
	author = {Kondor, Risi and Lin, Zhen and Trivedi, Shubhendu},
	year = {2018},
	keywords = {Convolution network, Spherical images},
	pages = {10},
	file = {Kondor et al. - Clebsch–Gordan Nets a Fully Fourier Space Spheric.pdf:/Users/wenhao/work/zotero/storage/ZJ74P2Z5/Kondor et al. - Clebsch–Gordan Nets a Fully Fourier Space Spheric.pdf:application/pdf},
}

@article{esteves_learning_2018,
	title = {Learning {SO}(3) {Equivariant} {Representations} with {Spherical} {CNNs}},
	url = {http://arxiv.org/abs/1711.06721},
	abstract = {We address the problem of 3D rotation equivariance in convolutional neural networks. 3D rotations have been a challenging nuisance in 3D classiﬁcation tasks requiring higher capacity and extended data augmentation in order to tackle it. We model 3D data with multivalued spherical functions and we propose a novel spherical convolutional network that implements exact convolutions on the sphere by realizing them in the spherical harmonic domain. Resulting ﬁlters have local symmetry and are localized by enforcing smooth spectra. We apply a novel pooling on the spectral domain and our operations are independent of the underlying spherical resolution throughout the network. We show that networks with much lower capacity and without requiring data augmentation can exhibit performance comparable to the state of the art in standard retrieval and classiﬁcation benchmarks.},
	language = {en},
	urldate = {2022-02-04},
	journal = {arXiv:1711.06721 [cs]},
	author = {Esteves, Carlos and Allen-Blanchette, Christine and Makadia, Ameesh and Daniilidis, Kostas},
	month = sep,
	year = {2018},
	note = {arXiv: 1711.06721},
	keywords = {Convolution network, Spherical images},
	file = {Esteves et al. - 2018 - Learning SO(3) Equivariant Representations with Sp.pdf:/Users/wenhao/work/zotero/storage/3ESYCMPC/Esteves et al. - 2018 - Learning SO(3) Equivariant Representations with Sp.pdf:application/pdf},
}

@article{qi_pointnet_2017,
	title = {{PointNet}++: {Deep} {Hierarchical} {Feature} {Learning} on {Point} {Sets} in a {Metric} {Space}},
	shorttitle = {{PointNet}++},
	url = {http://arxiv.org/abs/1706.02413},
	abstract = {Few prior works study deep learning on point sets. PointNet [20] is a pioneer in this direction. However, by design PointNet does not capture local structures induced by the metric space points live in, limiting its ability to recognize ﬁne-grained patterns and generalizability to complex scenes. In this work, we introduce a hierarchical neural network that applies PointNet recursively on a nested partitioning of the input point set. By exploiting metric space distances, our network is able to learn local features with increasing contextual scales. With further observation that point sets are usually sampled with varying densities, which results in greatly decreased performance for networks trained on uniform densities, we propose novel set learning layers to adaptively combine features from multiple scales. Experiments show that our network called PointNet++ is able to learn deep point set features efﬁciently and robustly. In particular, results signiﬁcantly better than state-of-the-art have been obtained on challenging benchmarks of 3D point clouds.},
	language = {en},
	urldate = {2022-02-04},
	journal = {arXiv:1706.02413 [cs]},
	author = {Qi, Charles R. and Yi, Li and Su, Hao and Guibas, Leonidas J.},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.02413},
	keywords = {Network on points},
	file = {Qi et al. - 2017 - PointNet++ Deep Hierarchical Feature Learning on .pdf:/Users/wenhao/work/zotero/storage/SJCGGUGU/Qi et al. - 2017 - PointNet++ Deep Hierarchical Feature Learning on .pdf:application/pdf},
}

@article{qi_pointnet_2017-1,
	title = {{PointNet}: {Deep} {Learning} on {Point} {Sets} for {3D} {Classification} and {Segmentation}},
	shorttitle = {{PointNet}},
	url = {http://arxiv.org/abs/1612.00593},
	abstract = {Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input. Our network, named PointNet, provides a uniﬁed architecture for applications ranging from object classiﬁcation, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efﬁcient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.},
	language = {en},
	urldate = {2022-02-04},
	journal = {arXiv:1612.00593 [cs]},
	author = {Qi, Charles R. and Su, Hao and Mo, Kaichun and Guibas, Leonidas J.},
	month = apr,
	year = {2017},
	note = {arXiv: 1612.00593},
	keywords = {Network on points},
	file = {Qi et al. - 2017 - PointNet Deep Learning on Point Sets for 3D Class.pdf:/Users/wenhao/work/zotero/storage/RGH2HU3Y/Qi et al. - 2017 - PointNet Deep Learning on Point Sets for 3D Class.pdf:application/pdf},
}

@article{kauderer-abrams_quantifying_2017,
	title = {Quantifying {Translation}-{Invariance} in {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1801.01450},
	abstract = {A fundamental problem in object recognition is the development of image representations that are invariant to common transformations such as translation, rotation, and small deformations. There are multiple hypotheses regarding the source of translation invariance in CNNs. One idea is that translation invariance is due to the increasing receptive ﬁeld size of neurons in successive convolution layers. Another possibility is that invariance is due to the pooling operation. We develop a simple a tool, the translation-sensitivity map, which we use to visualize and quantify the translation-invariance of various architectures. We obtain the surprising result that architectural choices such as the number of pooling layers and the convolution ﬁlter size have only a secondary effect on the translationinvariance of a network. Our analysis identiﬁes training data augmentation as the most important factor in obtaining translation-invariant representations of images using convolutional neural networks.},
	language = {en},
	urldate = {2022-02-02},
	journal = {arXiv:1801.01450 [cs]},
	author = {Kauderer-Abrams, Eric},
	month = dec,
	year = {2017},
	note = {arXiv: 1801.01450},
	keywords = {Convolution network},
	file = {Kauderer-Abrams - 2017 - Quantifying Translation-Invariance in Convolutiona.pdf:/Users/wenhao/work/zotero/storage/7JZQIQ2E/Kauderer-Abrams - 2017 - Quantifying Translation-Invariance in Convolutiona.pdf:application/pdf},
}
